{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPerb++5Dystiyi7Knp6RyQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathwikmethari/diffusers_ex_collab/blob/main/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhS1a3QmEqvH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "ddpm=DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\").to(\"cuda\")\n",
        "image=ddpm(num_inference_steps=100).images[0]\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_scheduler=DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\n",
        "unet=UNet2DModel.from_pretrained(\"google/ddpm-cat-256\").to(device)"
      ],
      "metadata": {
        "id": "SrONNaTIHQNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "could use .config to change the default values"
      ],
      "metadata": {
        "id": "r098WND5H8uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_scheduler.config"
      ],
      "metadata": {
        "id": "javkl8l7HzP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_scheduler.set_timesteps(50)# 50 time steps between 0 and 1000\n",
        "ddpm_scheduler.timesteps"
      ],
      "metadata": {
        "id": "U-CnUhiWE4br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet.config"
      ],
      "metadata": {
        "id": "Q0bYUluBImjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size=unet.config.sample_size\n",
        "noise = torch.randn((1, 3, sample_size, sample_size)).to(\"cuda\") #creating 1 batch, 3 channel, sample_size*sample_size noise image\n",
        "print(sample_size)"
      ],
      "metadata": {
        "id": "qKZ5AQBWHoaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meaning of .prev_sample:\n",
        "In the reverse process, at each time step\n",
        "t, the model predicts a denoised version of the noisy sample, and then computes the sample at the previous time step\n",
        "ùë•\n",
        "ùë°\n",
        "‚àí\n",
        "ùë•\n",
        "ùë°‚àí1\n",
        "‚Äã\n",
        " . That is:\n",
        "\n",
        "ùë•\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        "=\n",
        "some¬†function¬†of\n",
        "ùë•\n",
        "ùë°\n",
        "¬†and¬†predicted¬†noise\n",
        "\n",
        "So in many DDPM implementations, .prev_sample refers to the model‚Äôs estimate of the sample at the previous timestep.\n",
        "\n",
        "Usage:\n",
        ".prev_sample is commonly returned or stored during inference.\n",
        "\n",
        "It‚Äôs used to track the progression of the denoising chain from\n",
        "\n",
        "Some implementations (like Hugging Face‚Äôs Diffusers library) explicitly name this in their output objects."
      ],
      "metadata": {
        "id": "eiTjtd3OR2QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input=noise\n",
        "for time in ddpm_scheduler.timesteps:\n",
        "  with torch.inference_mode():\n",
        "    output_residual=unet(input,time).sample\n",
        "  input=ddpm_scheduler.step(output_residual,time,input).prev_sample"
      ],
      "metadata": {
        "id": "wJiBA_J8Is8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrlVfsSiAdZx"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "image = (input / 2 + 0.5).clamp(0, 1)\n",
        "image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
        "image = Image.fromarray((image * 255).round().astype(\"uint8\"))\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dskU22syUWki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}